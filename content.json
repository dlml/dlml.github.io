{"pages":[],"posts":[{"title":"winograd算法详解","text":"在计算机运行过程做加法速度比乘法快, 而在卷积神经网络中存在大量的矩阵乘法运算，此时winograd算法横空出世，能够很好的降低乘法次数，可谓加速的一把利器，其大量应用在前向预测框架上，比如ncnn、mace和mnn等。 ​以一维卷积$F(2,3)$为例，设输入信号为$d=[d_0\\quad d_1\\quad d_2\\quad d_3]^T$, 卷积核为$g=[g_0\\quad g_1\\quad g_2]^T$，滑动步长为1，不做pad操作，则输出结果可以写成 $$F(2,3)=\\left[\\begin{array}{ccc}d_0 &d_1 &d_2 \\\\d_1 &d_2 &d_3\\end{array}\\right]\\left[\\begin{array}{ccc}g_0 \\\\g_1\\\\g_2\\end{array}\\right]=\\left[\\begin{array}{c}r_0\\\\r_1\\end{array}\\right]$$ 其中 $$r_0=d_0*g_0+d_1*g_1+d_2*g_2$$ $$r_1=d_1*g_0+d_2*g_1+d_3*g_2$$ 可以可到如果用一般的矩阵乘法，则需要6次乘法和4次加法。 winograd做法如下 $$F(2,3)=\\left[\\begin{array}{ccc}d_0 &d_1 &d_2 \\\\d_1 &d_2 &d_3\\end{array}\\right]\\left[\\begin{array}{ccc}g_0 \\\\g_1\\\\g_2\\end{array}\\right]=\\left[\\begin{array}{c}m_1+m_2+m_3\\\\m_2-m_3-m_4\\end{array}\\right]$$ 其中 $$ m_1=(d_0-d_2)g_0, \\quad m_2=(d_1+d_2)\\frac{g_0+g_1+g_2}{2}\\\\ m_4=(d_1-d_3)g_2, \\quad m_3=(d_2-d_1)\\frac{g_0-g_1+g_2}{2}\\\\ $$ 可以看到利用winograd算法需要4次乘法，8次加法，相比一般矩阵乘法，通过增加加法运算减少乘法的运算，可以实现加速。 由于winograd算法证明比较复杂暂时不写了，直接丢计算公式，如下 $$Y=A^T\\left[[GgG^T]\\bigodot[B^TdB]\\right]A$$ 其中$\\bigodot$表示element-wise，$A,G,B$都是根据输出大小和卷积核提前确定好的，$g$表示卷积核，$d$表示输入数据(也就是需要进行卷积计算的数据)。","link":"/2019/07/03/winograd算法详解/"},{"title":"window安装cuda以及cudnn指南","text":"检查电脑是否正常安装驱动，对应驱动可以去nvidia官网查询下载更新，点击进入，安装完毕可以cmd中运行nvidia-smi，可以正常看到驱动的版本信息以及GPU的其他参数。 安装cuda，点击进入选择需要的版本，选择对应的系统平台，安装即可。 下载cudnn，根据对应cuda版本选择相应的cudnn即可，点击进入，将其解压，将对应的lib、include和x64文件夹中文件复制到NVIDIA GPU Computing Toolkit(比如cuda8，对应目录为C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0)对应的目录下即可。 安装相应的深度学习框架，不同的cuda版本对应着不同的框架版本，看官网说明即可。","link":"/2019/07/03/window安装cuda以及cudnn指南/"},{"title":"灰度图拉伸","text":"在OCR识别的时候，有时候由于背景和目标颜色太过于接近，而灰度拉伸就能发挥其作用，以下图展示了拉伸前和拉伸后的图像以及灰度直方图： 实现代码如下： 123456789101112131415161718192021222324252627282930313233343536#coding=utf-8import cv2def grey_scale(image,threshold): img_gray = cv2.cvtColor(image ,cv2.COLOR_RGB2GRAY) rows ,cols = img_gray.shape flat_gray = img_gray.reshape((cols * rows,)).tolist() #把数组压缩成一维的列表 flat_gray.sort() #将列表从小到大排序 a = flat_gray[int(threshold * len(flat_gray))] # threshold%分位数 b = flat_gray[int((1-threshold) * len(flat_gray))] # (1-threshold)%分位数 img_gray[img_gray&lt;a] = 0 img_gray[img_gray&gt;=b] = 255 return img_graysrc = cv2.imread(&apos;test.jpg&apos;)result = grey_scale(src,threshold=0.30)cv2.imwrite(&apos;test_result.jpg&apos;,result)#可视化展示import matplotlib.pyplot as pltimport matplotlibchinfo = matplotlib.font_manager.FontProperties(fname=&apos;C:/Windows/Fonts/msyh.ttc&apos;)plt.subplot(221)plt.imshow(src)plt.title(&apos;原始图&apos;,fontproperties=chinfo)plt.subplot(222)plt.imshow(result)plt.title(&apos;拉伸后结果图&apos;,fontproperties=chinfo)plt.subplot(223)plt.hist(src.ravel(), 256)plt.title(&apos;拉伸前&apos;,fontproperties=chinfo)plt.subplot(224)plt.hist(result.ravel(), 256)plt.title(&apos;拉伸后&apos;,fontproperties=chinfo)plt.show() 注：ravel()是将数组压缩成一维，便于画直方图，subplot函数“22*”便是在一张图上画两行两列的图像，依次是221-&gt;222-&gt;223-&gt;224。","link":"/2019/07/01/灰度图拉伸/"},{"title":"ncnn在window平台的使用方法","text":"ncnn是一种轻量的前向推理框架，广泛应用于移动端，而本篇博客主要介绍了其在pc端的使用方式。 1.编译protobuf 下载地址：点击进入下载 编译工具：vs2015 x64 本机工具命令提示符 123456&gt; cd &lt;protobuf-root-dir&gt;&gt; mkdir build-vs2015&gt; cd build-vs2015&gt; cmake -G&quot;NMake Makefiles&quot; -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=%cd%/install -Dprotobuf_BUILD_TESTS=OFF -Dprotobuf_MSVC_STATIC_RUNTIME=OFF ../cmake&gt; nmake&gt; nmake install 2.安装vulkan(pc上支持gpu加速) 下载地址：https://vulkan.lunarg.com 3.编译ncnn 1234567&gt; cd &lt;ncnn-root-dir&gt;&gt; mkdir -p build-vs2015&gt; cd build-vs2015&gt; cmake -G&quot;NMake Makefiles&quot; -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=%cd%/install -DProtobuf_INCLUDE_DIR=&lt;protobuf-root-dir&gt;/build-vs2015/install/include -DProtobuf_LIBRARIES=&lt;protobuf-root-dir&gt;/build-vs2015/install/lib/libprotobuf.lib -DProtobuf_PROTOC_EXECUTABLE=&lt;protobuf-root-dir&gt;/build-vs2017/install/bin/protoc.exe -DNCNN_VULKAN=ON ..&gt; nmake&gt; nmake install 1234567891011121314151617181920212223242526272829303132D:\\ncnn-20190628\\build&gt;cmake -G&quot;NMake Makefiles&quot; -DCMAKE_BUILD_TYPE=Release -DCAKE_INSTALL_PREFIX=%cd%/install -DProtobuf_INCLUDE_DIR=D:/protobuf-3.4.0/build_s2015/install/include -DProtobuf_LIBRARIES=D:/protobuf-3.4.0/build_vs2015/instal/lib/libprotobuf.lib -DProtobuf_PROTOC_EXECUTABLE=D:/protobuf-3.4.0/build_vs205/install/bin/protoc.exe -DNCNN_VULKAN=ON ..-- CMAKE_INSTALL_PREFIX = D:\\ncnn-20190628\\build/install-- The C compiler identification is MSVC 19.0.24215.1-- The CXX compiler identification is MSVC 19.0.24215.1-- Check for working C compiler: D:/Program Files/VS2015/VC/bin/amd64/cl.exe-- Check for working C compiler: D:/Program Files/VS2015/VC/bin/amd64/cl.exe --works-- Detecting C compiler ABI info-- Detecting C compiler ABI info - done-- Detecting C compile features-- Detecting C compile features - done-- Check for working CXX compiler: D:/Program Files/VS2015/VC/bin/amd64/cl.exe-- Check for working CXX compiler: D:/Program Files/VS2015/VC/bin/amd64/cl.exe- works-- Detecting CXX compiler ABI info-- Detecting CXX compiler ABI info - done-- Detecting CXX compile features-- Detecting CXX compile features - done-- Found OpenMP_C: -openmp (found version &quot;2.0&quot;)-- Found OpenMP_CXX: -openmp (found version &quot;2.0&quot;)-- Found OpenMP: TRUE (found version &quot;2.0&quot;)-- Found Vulkan: D:/VulkanSDK/1.1.92.1/Lib/vulkan-1.lib-- Found glslangValidator: D:/VulkanSDK/1.1.92.1/Bin/glslangValidator.exe-- Found Protobuf: D:/protobuf-3.4.0/build_vs2015/install/lib/libprotobuf.lib (ound version &quot;3.4.0&quot;)-- Configuring done-- Generating done-- Build files have been written to: D:/ncnn-20190628/build 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164D:\\ncnn-20190628\\build&gt;nmakeMicrosoft (R) 程序维护实用工具 14.00.24210.0 版版权所有 (C) Microsoft Corporation。 保留所有权利。Scanning dependencies of target generate-spirv[ 0%] Building SPIR-V module absval.spv[ 0%] Building SPIR-V module absval_fp16p.spv[ 0%] Building SPIR-V module absval_fp16s.spv[ 0%] Building SPIR-V module absval_fp16a.spv[ 0%] Building SPIR-V module absval_pack4.spv[ 1%] Building SPIR-V module absval_pack4_fp16p.spv[ 1%] Building SPIR-V module absval_pack4_fp16s.spv[ 1%] Building SPIR-V module absval_pack4_fp16a.spv[ 1%] Building SPIR-V module batchnorm.spv[ 1%] Building SPIR-V module batchnorm_fp16p.spv[ 2%] Building SPIR-V module batchnorm_fp16s.spv[ 2%] Building SPIR-V module batchnorm_fp16a.spv[ 2%] Building SPIR-V module batchnorm_pack4.spv[ 2%] Building SPIR-V module batchnorm_pack4_fp16p.spv[ 2%] Building SPIR-V module batchnorm_pack4_fp16s.spv[ 2%] Building SPIR-V module batchnorm_pack4_fp16a.spv[ 3%] Building SPIR-V module concat.spv[ 3%] Building SPIR-V module concat_fp16p.spv[ 3%] Building SPIR-V module concat_fp16s.spv[ 3%] Building SPIR-V module concat_fp16a.spv[ 3%] Building SPIR-V module concat_pack4.spv[ 3%] Building SPIR-V module concat_pack4_fp16p.spv[ 4%] Building SPIR-V module concat_pack4_fp16s.spv[ 4%] Building SPIR-V module concat_pack4_fp16a.spv[ 4%] Building SPIR-V module concat_pack4to1.spv[ 4%] Building SPIR-V module concat_pack4to1_fp16p.spv[ 4%] Building SPIR-V module concat_pack4to1_fp16s.spv[ 5%] Building SPIR-V module concat_pack4to1_fp16a.spv[ 5%] Building SPIR-V module convolution.spv[ 5%] Building SPIR-V module convolution_fp16p.spv[ 5%] Building SPIR-V module convolution_fp16s.spv[ 5%] Building SPIR-V module convolution_fp16a.spv[ 5%] Building SPIR-V module convolution_1x1s1d1.spv[ 6%] Building SPIR-V module convolution_1x1s1d1_fp16p.spv[ 6%] Building SPIR-V module convolution_1x1s1d1_fp16s.spv[ 6%] Building SPIR-V module convolution_1x1s1d1_fp16a.spv[ 6%] Building SPIR-V module convolution_pack1to4.spv[ 6%] Building SPIR-V module convolution_pack1to4_fp16p.spv[ 6%] Building SPIR-V module convolution_pack1to4_fp16s.spv[ 7%] Building SPIR-V module convolution_pack1to4_fp16a.spv[ 7%] Building SPIR-V module convolution_pack4.spv[ 7%] Building SPIR-V module convolution_pack4_fp16p.spv[ 7%] Building SPIR-V module convolution_pack4_fp16s.spv[ 7%] Building SPIR-V module convolution_pack4_fp16a.spv[ 8%] Building SPIR-V module convolution_pack4_1x1s1d1.spv[ 8%] Building SPIR-V module convolution_pack4_1x1s1d1_fp16p.spv[ 8%] Building SPIR-V module convolution_pack4_1x1s1d1_fp16s.spv[ 8%] Building SPIR-V module convolution_pack4_1x1s1d1_fp16a.spv[ 8%] Building SPIR-V module convolution_pack4_3x3s1d1_lds_8_8_2.spv[ 8%] Building SPIR-V module convolution_pack4_3x3s1d1_lds_8_8_2_fp16p.s[ 9%] Building SPIR-V module convolution_pack4_3x3s1d1_lds_8_8_2_fp16s.s[ 9%] Building SPIR-V module convolution_pack4_3x3s1d1_lds_8_8_2_fp16a.s[ 9%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_gemm.s[ 9%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_gemm_fv[ 9%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_gemm_fv[ 9%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_gemm_fv[ 10%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_transfut.spv[ 10%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_transfut_fp16p.spv[ 10%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_transfut_fp16s.spv[ 10%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_transfut_fp16a.spv[ 10%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_transfput.spv[ 11%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_transfput_fp16p.spv[ 11%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_transfput_fp16s.spv[ 11%] Building SPIR-V module convolution_pack4_3x3s1d1_winograd23_transfput_fp16a.spv[ 11%] Building SPIR-V module convolution_pack4to1.spv[ 11%] Building SPIR-V module convolution_pack4to1_fp16p.spv[ 11%] Building SPIR-V module convolution_pack4to1_fp16s.spv[ 12%] Building SPIR-V module convolution_pack4to1_fp16a.spv[ 12%] Building SPIR-V module crop.spv[ 12%] Building SPIR-V module crop_fp16p.spv[ 12%] Building SPIR-V module crop_fp16s.spv[ 12%] Building SPIR-V module crop_fp16a.spv[ 12%] Building SPIR-V module crop_pack4.spv[ 13%] Building SPIR-V module crop_pack4_fp16p.spv[ 13%] Building SPIR-V module crop_pack4_fp16s.spv[ 13%] Building SPIR-V module crop_pack4_fp16a.spv[ 13%] Building SPIR-V module deconvolution.spv[ 13%] Building SPIR-V module deconvolution_fp16p.spv[ 14%] Building SPIR-V module deconvolution_fp16s.spv[ 14%] Building SPIR-V module deconvolution_fp16a.spv[ 14%] Building SPIR-V module deconvolution_pack1to4.spv[ 14%] Building SPIR-V module deconvolution_pack1to4_fp16p.spv[ 14%] Building SPIR-V module deconvolution_pack1to4_fp16s.spv[ 14%] Building SPIR-V module deconvolution_pack1to4_fp16a.spv[ 15%] Building SPIR-V module deconvolution_pack4.spv[ 15%] Building SPIR-V module deconvolution_pack4_fp16p.spv[ 15%] Building SPIR-V module deconvolution_pack4_fp16s.spv[ 15%] Building SPIR-V module deconvolution_pack4_fp16a.spv[ 15%] Building SPIR-V module deconvolution_pack4to1.spv[ 15%] Building SPIR-V module deconvolution_pack4to1_fp16p.spv[ 16%] Building SPIR-V module deconvolution_pack4to1_fp16s.spv[ 16%] Building SPIR-V module deconvolution_pack4to1_fp16a.spv[ 16%] Building SPIR-V module dropout.spv[ 16%] Building SPIR-V module dropout_fp16p.spv[ 16%] Building SPIR-V module dropout_fp16s.spv[ 17%] Building SPIR-V module dropout_fp16a.spv[ 17%] Building SPIR-V module dropout_pack4.spv[ 17%] Building SPIR-V module dropout_pack4_fp16p.spv[ 17%] Building SPIR-V module dropout_pack4_fp16s.spv[ 17%] Building SPIR-V module dropout_pack4_fp16a.spv[ 17%] Building SPIR-V module eltwise.spv[ 18%] Building SPIR-V module eltwise_fp16p.spv[ 18%] Building SPIR-V module eltwise_fp16s.spv[ 18%] Building SPIR-V module eltwise_fp16a.spv[ 18%] Building SPIR-V module eltwise_pack4.spv[ 18%] Building SPIR-V module eltwise_pack4_fp16p.spv[ 19%] Building SPIR-V module eltwise_pack4_fp16s.spv[ 19%] Building SPIR-V module eltwise_pack4_fp16a.spv[ 19%] Building SPIR-V module flatten.spv[ 19%] Building SPIR-V module flatten_fp16p.spv[ 19%] Building SPIR-V module flatten_fp16s.spv[ 19%] Building SPIR-V module flatten_fp16a.spv[ 20%] Building SPIR-V module flatten_pack1to4.spv[ 20%] Building SPIR-V module flatten_pack1to4_fp16p.spv[ 20%] Building SPIR-V module flatten_pack1to4_fp16s.spv[ 20%] Building SPIR-V module flatten_pack1to4_fp16a.spv[ 20%] Building SPIR-V module flatten_pack4.spv[ 20%] Building SPIR-V module flatten_pack4_fp16p.spv[ 21%] Building SPIR-V module flatten_pack4_fp16s.spv[ 21%] Building SPIR-V module flatten_pack4_fp16a.spv[ 21%] Building SPIR-V module innerproduct.spv[ 21%] Building SPIR-V module innerproduct_fp16p.spv[ 21%] Building SPIR-V module innerproduct_fp16s.spv[ 22%] Building SPIR-V module innerproduct_fp16a.spv[ 22%] Building SPIR-V module innerproduct_pack1to4.spv[ 22%] Building SPIR-V module innerproduct_pack1to4_fp16p.spv[ 22%] Building SPIR-V module innerproduct_pack1to4_fp16s.spv[ 22%] Building SPIR-V module innerproduct_pack1to4_fp16a.spv[ 22%] Building SPIR-V module innerproduct_pack4.spv[ 23%] Building SPIR-V module innerproduct_pack4_fp16p.spv[ 23%] Building SPIR-V module innerproduct_pack4_fp16s.spv[ 23%] Building SPIR-V module innerproduct_pack4_fp16a.spv[ 23%] Building SPIR-V module innerproduct_pack4_lds_64.spv[ ...][ 99%] Building CXX object tools/onnx/CMakeFiles/onnx2ncnn.dir/onnx.pb.cc.objonnx.pb.ccD:\\protobuf-3.4.0\\build_vs2015\\install\\include\\google/protobuf/io/coded_stream.h(870): warning C4800: “google::protobuf::internal::AtomicWord”: 将值强制为布尔值“true”或“false”(性能警告)D:\\protobuf-3.4.0\\build_vs2015\\install\\include\\google/protobuf/io/coded_stream.h(874): warning C4800: “google::protobuf::internal::Atomic64”: 将值强制为布尔值“true”或“false”(性能警告)D:\\protobuf-3.4.0\\build_vs2015\\install\\include\\google/protobuf/generated_message_util.h(160): warning C4800: “google::protobuf::uint32”: 将值强制为布尔值“true”或“false”(性能警告)[100%] Linking CXX executable onnx2ncnn.exe[100%] Built target onnx2ncnn 123456789101112131415161718192021222324252627282930313233D:\\ncnn-20190628\\build&gt;nmake installMicrosoft (R) 程序维护实用工具 14.00.24210.0 版版权所有 (C) Microsoft Corporation。 保留所有权利。[ 77%] Built target generate-spirv[ 97%] Built target ncnn[ 97%] Built target benchncnn[ 98%] Built target ncnnoptimize[ 98%] Built target ncnn2mem[ 99%] Built target caffe2ncnn[ 99%] Built target mxnet2ncnn[100%] Built target onnx2ncnnInstall the project...-- Install configuration: &quot;Release&quot;-- Installing: D:/ncnn-20190628/build/install/lib/ncnn.lib-- Installing: D:/ncnn-20190628/build/install/include/allocator.h-- Installing: D:/ncnn-20190628/build/install/include/blob.h-- Installing: D:/ncnn-20190628/build/install/include/command.h-- Installing: D:/ncnn-20190628/build/install/include/cpu.h-- Installing: D:/ncnn-20190628/build/install/include/gpu.h-- Installing: D:/ncnn-20190628/build/install/include/layer.h-- Installing: D:/ncnn-20190628/build/install/include/layer_type.h-- Installing: D:/ncnn-20190628/build/install/include/mat.h-- Installing: D:/ncnn-20190628/build/install/include/modelbin.h-- Installing: D:/ncnn-20190628/build/install/include/net.h-- Installing: D:/ncnn-20190628/build/install/include/opencv.h-- Installing: D:/ncnn-20190628/build/install/include/option.h-- Installing: D:/ncnn-20190628/build/install/include/paramdict.h-- Installing: D:/ncnn-20190628/build/install/include/pipeline.h-- Installing: D:/ncnn-20190628/build/install/include/benchmark.h-- Installing: D:/ncnn-20190628/build/install/include/layer_type_enum.h-- Installing: D:/ncnn-20190628/build/install/include/platform.h 4.测试一下，将编译好的benchmark.exe复制到根目录benchmark文件夹中，然后运行如下命令 12345678910111213141516171819202122232425D:\\ncnn-20190628\\benchmark&gt;benchncnn.exe[0 GeForce GTX 970] queueC=0[16] queueT=1[2] memU=4294967295 memDL=7 memHV=9[0 GeForce GTX 970] fp16p=1 fp16s=1 fp16a=0 int8s=1 int8a=1loop_count = 4num_threads = 4powersave = 0gpu_device = -1 squeezenet min = 43.21 max = 46.93 avg = 44.39 squeezenet_int8 min = 57.67 max = 70.70 avg = 61.82 mobilenet min = 53.84 max = 68.20 avg = 59.21 mobilenet_int8 min = 88.39 max = 96.28 avg = 92.16 mobilenet_v2 min = 60.08 max = 62.36 avg = 61.50 shufflenet min = 17.35 max = 18.38 avg = 17.76 mnasnet min = 49.47 max = 52.29 avg = 50.60 proxylessnasnet min = 65.89 max = 66.47 avg = 66.20 googlenet min = 132.48 max = 135.69 avg = 133.85 googlenet_int8 min = 191.08 max = 194.21 avg = 192.58 resnet18 min = 126.42 max = 128.72 avg = 127.54 resnet18_int8 min = 162.66 max = 170.55 avg = 165.19 alexnet min = 90.18 max = 258.30 avg = 159.68 vgg16 min = 856.14 max = 878.42 avg = 863.20 vgg16_int8 min = 1119.27 max = 1130.59 avg = 1124.57 resnet50 min = 302.27 max = 313.23 avg = 306.50 resnet50_int8 min = 428.14 max = 431.83 avg = 430.05","link":"/2019/07/01/ncnn在window平台的使用方法/"}],"tags":[{"name":"winograd","slug":"winograd","link":"/tags/winograd/"},{"name":"cuda","slug":"cuda","link":"/tags/cuda/"},{"name":"图像拉伸","slug":"图像拉伸","link":"/tags/图像拉伸/"},{"name":"ncnn","slug":"ncnn","link":"/tags/ncnn/"}],"categories":[]}